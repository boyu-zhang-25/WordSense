{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import string\n",
    "import itertools\n",
    "from io import open\n",
    "from conllu import parse_incr\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom torch.autograd import Variable\\nimport torch.optim as optim\\nsense_vec = Variable(torch.randn(10, 1), requires_grad = True)\\n# sense_vec.retain_grad()\\ndef_vec = Variable(torch.randn(10, 1), requires_grad = True)\\nk = 2*sense_vec\\n# def_vec.retain_grad()\\nopt = torch.optim.Adam([sense_vec, def_vec])\\nmse = torch.nn.MSELoss()\\npdist = torch.nn.PairwiseDistance(p = 2)\\ncos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\\n\\nfor i in range(10):\\n    \\n    opt.zero_grad()\\n    \\n    loss = mse(sense_vec, def_vec)\\n    loss.backward()\\n    \\n    print('pdist: {}'.format(pdist(sense_vec, def_vec)))\\n    print('pdist type: {}'.format(type(pdist(sense_vec, def_vec))))\\n    # print('loss: {}'.format(def_vec))\\n    opt.step()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "sense_vec = Variable(torch.randn(10, 1), requires_grad = True)\n",
    "# sense_vec.retain_grad()\n",
    "def_vec = Variable(torch.randn(10, 1), requires_grad = True)\n",
    "k = 2*sense_vec\n",
    "# def_vec.retain_grad()\n",
    "opt = torch.optim.Adam([sense_vec, def_vec])\n",
    "mse = torch.nn.MSELoss()\n",
    "pdist = torch.nn.PairwiseDistance(p = 2)\n",
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    loss = mse(sense_vec, def_vec)\n",
    "    loss.backward()\n",
    "    \n",
    "    print('pdist: {}'.format(pdist(sense_vec, def_vec)))\n",
    "    print('pdist type: {}'.format(type(pdist(sense_vec, def_vec))))\n",
    "    # print('loss: {}'.format(def_vec))\n",
    "    opt.step()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "return: \n",
    "all sentences\n",
    "target word index\n",
    "target word lemma\n",
    "target word sense\n",
    "all senses for each word \n",
    "from the EUD for train, test, and dev dataset\n",
    "index provided by WSD dataset by White et. al.\n",
    "'''\n",
    "# get all the senses and definitions for each word from WSD dataset\n",
    "# order of senses and definitions are in order\n",
    "def get_all_senses_and_definitions(wsd_data):\n",
    "\n",
    "    # all senses for each \n",
    "    all_senses = {}\n",
    "    all_definitions = {}\n",
    "    \n",
    "    # for test purpose: only load specific amount of data\n",
    "    for i in range(45):\n",
    "\n",
    "        # get the original sentence from EUD\n",
    "        sentence_id = wsd_data[i].get('Sentence.ID')\n",
    "        \n",
    "        # remove punctuations from definitions?\n",
    "        definition = wsd_data[i].get('Sense.Definition').translate(str.maketrans('', '', string.punctuation)).split(' ')\n",
    "        \n",
    "        # the index in EUD is 1-based!!!\n",
    "        sentence_number = int(sentence_id.split(' ')[-1]) - 1\n",
    "        word_index = int(wsd_data[i].get('Arg.Token')) - 1\n",
    "        word_lemma = wsd_data[i].get('Arg.Lemma')\n",
    "        word_sense = wsd_data[i].get('Synset')\n",
    "        response = wsd_data[i].get('Sense.Response')\n",
    "\n",
    "        # if the word already exits: add the new sense to the list\n",
    "        # else: creata a new list for the word\n",
    "        if word_lemma in all_senses.keys():\n",
    "            if word_sense not in all_senses[word_lemma]:\n",
    "                all_senses[word_lemma].append(word_sense)\n",
    "        else:\n",
    "            all_senses[word_lemma] = []\n",
    "            all_senses[word_lemma].append(word_sense)            \n",
    "            \n",
    "        if word_lemma in all_definitions.keys():\n",
    "            if definition not in all_definitions[word_lemma]:\n",
    "                # split to list before store\n",
    "                all_definitions[word_lemma].append(definition)\n",
    "        else:\n",
    "            all_definitions[word_lemma] = []\n",
    "            all_definitions[word_lemma].append(definition)\n",
    "        \n",
    "    return all_senses, all_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the WSD dataset first\n",
    "# and retrieve all sentences from the EUD\n",
    "\n",
    "'''\n",
    "Copyright@\n",
    "White, A. S., D. Reisinger, K. Sakaguchi, T. Vieira, S. Zhang, R. Rudinger, K. Rawlins, & B. Van Durme. 2016. \n",
    "[Universal decompositional semantics on universal dependencies]\n",
    "(http://aswhite.net/media/papers/white_universal_2016.pdf). \n",
    "To appear in *Proceedings of the Conference on Empirical Methods in Natural Language Processing 2016*.\n",
    "'''\n",
    "\n",
    "# parse the WSD dataset and construct X_Y tensors\n",
    "def parse_data():\n",
    "\n",
    "    # parse the EUD-EWT conllu files and retrieve the sentences\n",
    "    # remove all punctuation?\n",
    "    train_file = open(\"data/UD_English-EWT/en_ewt-ud-train.conllu\", \"r\", encoding=\"utf-8\")\n",
    "    train_data = list(parse_incr(train_file))\n",
    "    # train_data = [[''.join(c for c in word.get('lemma') if c not in string.punctuation) for word in token_list] for token_list in train_data]\n",
    "    # train_data = [[word for word in s if word] for s in train_data]\n",
    "    print('Parsed {} training data from UD_English-EWT/en_ewt-ud-train.conllu.'.format(len(train_data)))\n",
    "\n",
    "    test_file = open(\"data/UD_English-EWT/en_ewt-ud-test.conllu\", \"r\", encoding=\"utf-8\")\n",
    "    test_data = list(parse_incr(test_file))\n",
    "    # test_data = [[''.join(c for c in word.get('lemma') if c not in string.punctuation) for word in token_list] for token_list in test_data]\n",
    "    # test_data = [[word for word in s if word] for s in test_data]\n",
    "    print('Parsed {} testing data from UD_English-EWT/en_ewt-ud-test.conllu.'.format(len(test_data)))\n",
    "\n",
    "    dev_file = open(\"data/UD_English-EWT/en_ewt-ud-dev.conllu\", \"r\", encoding=\"utf-8\")\n",
    "    dev_data = list(parse_incr(dev_file))\n",
    "    # dev_data = [[''.join(c for c in word.get('lemma') if c not in string.punctuation) for word in token_list] for token_list in dev_data]\n",
    "    # dev_data = [[word for word in s if word] for s in dev_data]\n",
    "    print('Parsed {} dev data from UD_English-EWT/en_ewt-ud-dev.conllu.'.format(len(dev_data)))\n",
    "\n",
    "    # parse the WSD dataset\n",
    "    wsd_data = []\n",
    "\n",
    "    # read in tsv by White et. al., 2016\n",
    "    with open('data/wsd/wsd_eng_ud1.2_10262016.tsv', mode = 'r') as wsd_file:\n",
    "\n",
    "        tsv_reader = csv.DictReader(wsd_file, delimiter = '\\t')      \n",
    "\n",
    "        # store the data: ordered dict row\n",
    "        for row in tsv_reader:                                \n",
    "\n",
    "            # each data vector\n",
    "            wsd_data.append(row)\n",
    "\n",
    "        # make sure all data are parsed\n",
    "        print('Parsed {} word sense data from White et. al., 2016.'.format(len(wsd_data)))\n",
    "\n",
    "    return wsd_data, train_data, test_data, dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 12543 training data from UD_English-EWT/en_ewt-ud-train.conllu.\n",
      "Parsed 2077 testing data from UD_English-EWT/en_ewt-ud-test.conllu.\n",
      "Parsed 2002 dev data from UD_English-EWT/en_ewt-ud-dev.conllu.\n",
      "Parsed 439312 word sense data from White et. al., 2016.\n"
     ]
    }
   ],
   "source": [
    "# parse the data\n",
    "wsd_data, train_data, test_data, dev_data = parse_data()\n",
    "\n",
    "# return the raw sentences from the EUD for train, test, and dev\n",
    "# test the first 20 sentences\n",
    "all_senses, all_definitions = get_all_senses_and_definitions(wsd_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Construct the X and Y for train, dev, and test from White et. al., 2016\n",
    "For each anonator and each word, on pair of data and label will be created\n",
    "Warning: code here is hard to read LMAO\n",
    "'''\n",
    "def construct_X_Y(all_senses, all_definitions, train_data, dev_data, test_data):\n",
    "    \n",
    "    wsd_data = []\n",
    "    \n",
    "    with open('data/wsd/wsd_eng_ud1.2_10262016.tsv', mode = 'r') as wsd_file:\n",
    "        \n",
    "        tsv_reader = csv.DictReader(wsd_file, delimiter = '\\t')\n",
    "        \n",
    "        # same annotator and same sentence number will generate on pair of X_Y\n",
    "        # manually set the first sentence from White et. al., 2016\n",
    "        current_annotator = '0'\n",
    "        current_sentence_num = '1364'\n",
    "        current_Y = [0 for _ in range(len(all_senses['spring']))]           \n",
    "        sentence = train_data[1363]\n",
    "        \n",
    "        # word from the EUD is a ordered dict for word properties\n",
    "        # use key 'lemma' to get the literal representations\n",
    "        current_X = [word.get('lemma') for word in sentence]\n",
    "        current_idx = 12\n",
    "        \n",
    "        # lists X and Y\n",
    "        train_X, test_X, dev_X = ([] for i in range(3))\n",
    "        train_Y, test_Y, dev_Y = ([] for i in range(3))\n",
    "        train_word_idx, test_word_idx, dev_word_idx = ([] for i in range(3))\n",
    "\n",
    "        for idx, row in enumerate(tsv_reader):\n",
    "                        \n",
    "            # training set; only test first 30 training sentences for now\n",
    "            if idx < 45 and row['Split'] == 'train':\n",
    "                \n",
    "                # if still is the same annotatior, word index, target word\n",
    "                # modify Y with the sense reponse\n",
    "                if current_annotator == row['Annotator.ID'] and current_idx == int(row['Arg.Token']) - 1 and current_sentence_num == row['Sentence.ID'].split(' ')[-1]:\n",
    "                    \n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                \n",
    "                # if switch annotator or target word\n",
    "                # append the Y and X from the last annotator and word\n",
    "                # start a new Y and X for the current annotator and target\n",
    "                else:\n",
    "                    # print('h2: {}'.format(idx))\n",
    "                    # sentence\n",
    "                    train_X.append(current_X)\n",
    "                    # annotator responses, e.g., [1, 0, ...]\n",
    "                    train_Y.append(current_Y)\n",
    "                    train_word_idx.append(current_idx)\n",
    "                    \n",
    "                    current_annotator = row['Annotator.ID']\n",
    "                    current_sentence_num = row['Sentence.ID'].split(' ')[-1]\n",
    "                    \n",
    "                    current_idx = int(row['Arg.Token']) - 1\n",
    "                    current_Y = [0 for _ in range(len(all_senses[row['Arg.Lemma']]))]\n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                    \n",
    "                    sentence_id = row['Sentence.ID']\n",
    "                    sentence_number = int(sentence_id.split(' ')[-1]) - 1\n",
    "                    sentence = train_data[sentence_number]\n",
    "                    current_X = [word.get('lemma') for word in sentence]\n",
    "                    \n",
    "            # testing set\n",
    "            elif idx < 45 and row['Split'] == 'test':\n",
    "                \n",
    "                if current_annotator == row['Annotator.ID'] and current_idx == int(row['Arg.Token']) - 1 and current_sentence_num == row['Sentence.ID'].split(' ')[-1]:\n",
    "                    \n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                else:\n",
    "                    test_X.append(current_X)\n",
    "                    test_Y.append(current_Y)\n",
    "                    test_word_idx.append(current_idx)\n",
    "\n",
    "                    current_annotator = row['Annotator.ID']\n",
    "                    current_sentence_num = row['Sentence.ID'].split(' ')[-1]\n",
    "\n",
    "                    current_idx = int(row['Arg.Token']) - 1\n",
    "                    current_Y = [0 for _ in range(len(all_senses[row['Arg.Lemma']]))]\n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                    \n",
    "                    sentence_id = row['Sentence.ID']\n",
    "                    sentence_number = int(sentence_id.split(' ')[-1]) - 1\n",
    "                    sentence = test_data[sentence_number]\n",
    "                    current_X = [word.get('lemma') for word in sentence]\n",
    "                    \n",
    "            # dev set       \n",
    "            elif idx < 45:\n",
    "                if current_annotator == row['Annotator.ID'] and current_idx == int(row['Arg.Token']) - 1 and current_sentence_num == row['Sentence.ID'].split(' ')[-1]:\n",
    "                    \n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                else:\n",
    "                    dev_X.append(current_X)\n",
    "                    dev_Y.append(current_Y)\n",
    "                    dev_word_idx.append(current_idx)\n",
    "\n",
    "                    current_annotator = row['Annotator.ID']\n",
    "                    current_sentence_num = row['Sentence.ID'].split(' ')[-1]\n",
    "\n",
    "                    current_idx = int(row['Arg.Token']) - 1\n",
    "                    current_Y = [0 for _ in range(len(all_senses[row['Arg.Lemma']]))]\n",
    "                    sense_idx = all_senses[row['Arg.Lemma']].index(row['Synset'])\n",
    "                    if row['Sense.Response'] == 'True':\n",
    "                        current_Y[sense_idx] = 1\n",
    "                    else:\n",
    "                        current_Y[sense_idx] = 0\n",
    "                    \n",
    "                    sentence_id = row['Sentence.ID']\n",
    "                    sentence_number = int(sentence_id.split(' ')[-1]) - 1\n",
    "                    sentence = dev_data[sentence_number]\n",
    "                    current_X = [word.get('lemma') for word in sentence]\n",
    "        \n",
    "        print('\\n******************* Data Example ***********************')\n",
    "        print('Sentence: {}'.format(train_X[0]))\n",
    "        print('Annotator Response, i.e., true label: {}'.format(train_Y[0]))\n",
    "        print('Target Word Index: {}'.format(train_word_idx[0]))\n",
    "        print('All senses for the target word: {}'.format(all_senses[train_X[0][train_word_idx[0]]]))\n",
    "        print('All definitions (in order of its senses from WordNet): {}'.format(all_definitions[train_X[0][train_word_idx[0]]]))\n",
    "        print('********************************************************')\n",
    "        \n",
    "        return train_X, test_X, dev_X, train_Y, test_Y, dev_Y, train_word_idx, test_word_idx, dev_word_idx\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************* Data Example ***********************\n",
      "Sentence: ['on', 'August', '9', ',', '2004', ',', 'it', 'be', 'announce', 'that', 'in', 'the', 'spring', 'of', '2001', ',', 'a', 'man', 'name', 'El', '-', 'Shukrijumah', ',', 'also', 'know', 'as', 'Jafar', 'the', 'Pilot', ',', 'who', 'be', 'part', 'of', 'a', '\"', 'second', 'wave', ',', '\"', 'have', 'be', 'case', 'New', 'York', 'City', 'helicopter', '.']\n",
      "Annotator Response, i.e., true label: [1, 0, 0, 0, 0, 0]\n",
      "Target Word Index: 12\n",
      "All senses for the target word: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "All definitions (in order of its senses from WordNet): [['the', 'season', 'of', 'growth'], ['a', 'metal', 'elastic', 'device', 'that', 'returns', 'to', 'its', 'shape', 'or', 'position', 'when', 'pushed', 'or', 'pulled', 'or', 'pressed'], ['a', 'natural', 'flow', 'of', 'ground', 'water'], ['a', 'point', 'at', 'which', 'water', 'issues', 'forth'], ['the', 'elasticity', 'of', 'something', 'that', 'can', 'be', 'stretched', 'and', 'returns', 'to', 'its', 'original', 'length'], ['a', 'light', 'selfpropelled', 'movement', 'upwards', 'or', 'forwards']]\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "# get the X and Y for models\n",
    "train_X, test_X, dev_X, train_Y, test_Y, dev_Y, train_word_idx, test_word_idx, dev_word_idx = construct_X_Y(all_senses, all_definitions, train_data, dev_data, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from model import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELMo setup\n",
    "# ELMo is tuned to lower dimension (256) by MLP in Model\n",
    "elmo = ElmoEmbedder()\n",
    "\n",
    "# model and trainer\n",
    "epochs = 10\n",
    "trainer = Trainer(epochs = epochs, elmo_class = elmo, all_senses = all_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############   Model Parameters   ##############\n",
      "layers.word_sense.0.weight torch.Size([512, 512])\n",
      "layers.word_sense.0.bias torch.Size([512])\n",
      "layers.word_sense.2.weight torch.Size([300, 512])\n",
      "layers.word_sense.2.bias torch.Size([300])\n",
      "dimension_reduction_MLP.weight torch.Size([256, 3072])\n",
      "dimension_reduction_MLP.bias torch.Size([256])\n",
      "wsd_lstm.weight_ih_l0 torch.Size([1024, 256])\n",
      "wsd_lstm.weight_hh_l0 torch.Size([1024, 256])\n",
      "wsd_lstm.bias_ih_l0 torch.Size([1024])\n",
      "wsd_lstm.bias_hh_l0 torch.Size([1024])\n",
      "wsd_lstm.weight_ih_l0_reverse torch.Size([1024, 256])\n",
      "wsd_lstm.weight_hh_l0_reverse torch.Size([1024, 256])\n",
      "wsd_lstm.bias_ih_l0_reverse torch.Size([1024])\n",
      "wsd_lstm.bias_hh_l0_reverse torch.Size([1024])\n",
      "wsd_lstm.weight_ih_l1 torch.Size([1024, 512])\n",
      "wsd_lstm.weight_hh_l1 torch.Size([1024, 256])\n",
      "wsd_lstm.bias_ih_l1 torch.Size([1024])\n",
      "wsd_lstm.bias_hh_l1 torch.Size([1024])\n",
      "wsd_lstm.weight_ih_l1_reverse torch.Size([1024, 512])\n",
      "wsd_lstm.weight_hh_l1_reverse torch.Size([1024, 256])\n",
      "wsd_lstm.bias_ih_l1_reverse torch.Size([1024])\n",
      "wsd_lstm.bias_hh_l1_reverse torch.Size([1024])\n",
      "definition_embeddings.ambition torch.Size([300, 2])\n",
      "definition_embeddings.house torch.Size([300, 12])\n",
      "definition_embeddings.management torch.Size([300, 2])\n",
      "definition_embeddings.overthrow torch.Size([300, 2])\n",
      "definition_embeddings.spring torch.Size([300, 6])\n",
      "##################################################\n",
      "[Epoch: 1/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cdf6b2b54d4bf3a8af5b4fe1f90b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 1, Mean Train Loss: -2.7887331694364548\n",
      "[Epoch: 2/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e333b5ebe26471db3942aa30e147070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 2, Mean Train Loss: -8.484513223171234\n",
      "[Epoch: 3/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f989bc616114ad1bd97a8c7a25fc48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 3, Mean Train Loss: -237.8154919743538\n",
      "[Epoch: 4/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382f876ff0064842a46f0130ff7b0600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 4, Mean Train Loss: -2092.7777383551\n",
      "[Epoch: 5/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b44d16b30f34a08a89ec0ce8c8a8253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 5, Mean Train Loss: -10235.80887902528\n",
      "[Epoch: 6/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12242d73773441bd968265e13969abed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 6, Mean Train Loss: -37010.78529950231\n",
      "[Epoch: 7/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183c76ea00b14ac195c0112a9bd23cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 7, Mean Train Loss: -107990.52574662864\n",
      "[Epoch: 8/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa1a4e09fd47f3803686e471598892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 8, Mean Train Loss: -268544.99331615865\n",
      "[Epoch: 9/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64dbe94face44c4b3d572ada4554b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 9, Mean Train Loss: -591657.5999565125\n",
      "[Epoch: 10/10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c65dfe46e24c86a32c66cef6408651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: spring\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['spring.n.01', 'spring.n.02', 'spring.n.03', 'spring.n.04', 'give.n.01', 'leap.n.01']\n",
      "\n",
      "Word lemma: ambition\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['ambition.n.01', 'ambition.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: management\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['management.n.01', 'management.n.02']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: house\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['house.n.01', 'firm.n.01', 'house.n.03', 'house.n.04', 'house.n.05', 'house.n.06', 'house.n.07', 'sign_of_the_zodiac.n.01', 'house.n.09', 'family.n.01', 'theater.n.01', 'house.n.12']\n",
      "\n",
      "Word lemma: overthrow\n",
      "Word sense embedding size: torch.Size([300])\n",
      "All its senses: ['overthrow.n.01', 'upset.n.02']\n",
      "\n",
      "Epoch: 10, Mean Train Loss: -1183882.7408469766\n"
     ]
    }
   ],
   "source": [
    "train_losses, dev_losses, dev_rs, distance = trainer.train(train_X, train_Y, train_word_idx, dev_X, dev_Y, dev_word_idx, development = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntitle = \"Distance between sense vec. and definition vec.\"\\nplt.title(title)\\nplt.ylabel(\\'L2 distance\\')\\nplt.xlabel(\\'Number of Iteration\\')\\nplt.plot(distance, label = \"Distance\")\\nplt.legend(loc = \"best\")\\nplt.savefig(\\'distance.png\\')\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the learning curve\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "ite = [e for e in range(epochs)]\n",
    "plt.plot(train_losses, label = \"Training Loss by L2\")\n",
    "plt.legend(loc = \"best\")\n",
    "title = \"Learning Curve (# of training examples \" + str(len(train_X)) + \")\"\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.savefig('loss.png')\n",
    "'''\n",
    "title = \"Distance between sense vec. and definition vec.\"\n",
    "plt.title(title)\n",
    "plt.ylabel('L2 distance')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.plot(distance, label = \"Distance\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.savefig('distance.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
